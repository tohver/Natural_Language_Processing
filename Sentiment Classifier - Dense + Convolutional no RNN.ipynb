{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Classifier -Convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,  Flatten, Dropout, Conv1D, GlobalMaxPooling1D, SpatialDropout1D\n",
    "from keras.layers import Embedding \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='model_output/conv'\n",
    "\n",
    "epochs=4\n",
    "batch_size=128 #mini b.s. for Gradient Descent, for start\n",
    "\n",
    "# for Vector Space Embeddings: \n",
    "\n",
    "n_dim=64 # number of dimensions\n",
    "n_unique_words = 5000\n",
    "n_words_to_skip= 50 # the most common word, skip the top 50\n",
    "max_review_length =400 # if review has more than 100 words: truncate; the longer the review = longer train &...\n",
    "\n",
    "drop_embed=0.2  #dropout into the embedding layer, to randomly dropout 20%; to avoid overfitting\n",
    "pad_type=  trunc_type='pre' # what kind of padding / truncating'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### NN architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dense=256\n",
    "dropout=0.2\n",
    "\n",
    "n_conv = 256 # nr of kernels in the conv. layer\n",
    "k_conv=3  # size of the filter, here: 1-dimensional; sequences of 3 words in a row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data \n",
    "\n",
    "in one line: \n",
    "* set the max. number of tokens in each of documents, \n",
    "* filters out punctuation, \n",
    "* sets all tokens to lowercase, \n",
    "* converts all words into an integer index\n",
    "<br>\n",
    "= keras.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) =  imdb.load_data(num_words=n_unique_words)\n",
    "                                #no skipped words, they can be important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore words from index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=keras.datasets.imdb.get_word_index()\n",
    "word_index={k:(v+3) for k,v in word_index.items()}\n",
    "word_index['PAD']=0\n",
    "word_index['START']=1\n",
    "word_index['UNK']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'must'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index={v:k for k,v in word_index.items()}\n",
    "word_index[215]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(w_x_train,_), (w_x_valid,_)=imdb.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data \n",
    "we dediced that sequences longer than 100 will bo truncated to 100 tokens\n",
    "and if shorter than 100: will be padded up to 100<br>\n",
    "we truncate the front of the reviews away\n",
    "<br> and we take the value of 0 for our padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pad_sequences(X_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type)\n",
    "X_test=pad_sequences(X_test, maxlen=max_review_length, padding=pad_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(n_unique_words, # creating Vector Space from text, in a single step\n",
    "                  n_dim, input_length=max_review_length)) \n",
    "model.add(SpatialDropout1D(drop_embed)) # dropout to the embedding layer; 20% of the neurons\n",
    "model.add(Conv1D (n_conv, k_conv, activation='relu'))\n",
    "    # no need for model.add(Flatten()) \n",
    "model.add(GlobalMaxPooling1D()) # reduce the dimensionality \n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid')) # 2 classes, = sigmoid neuron is ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews fitted into embedding layer, which converts the language into **vector space embedding**\n",
    "<br>Dense layer will learn which word vector representations are predictive of whether it is a positive or negative review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 400, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 398, 256)          49408     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 435,457\n",
      "Trainable params: 435,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fewer parameters, we had 700 000 in dense l., here only 400 000 <br>\n",
    "= the efficiency of the convolutional layers, more dense calculations then dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',    #what kind of loss we are going to have, this is v. efficient\n",
    "                                   # przy MNIST by≈Ç categorical_crossentropy - for multiclass problems    \n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 150s 6ms/step - loss: 0.4922 - acc: 0.7402 - val_loss: 0.2957 - val_acc: 0.8743\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 142s 6ms/step - loss: 0.2533 - acc: 0.8983 - val_loss: 0.2547 - val_acc: 0.8948\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 148s 6ms/step - loss: 0.1676 - acc: 0.9380 - val_loss: 0.2628 - val_acc: 0.8940\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 156s 6ms/step - loss: 0.1133 - acc: 0.9610 - val_loss: 0.2839 - val_acc: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x200ef35eac8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(output_dir+'/weights.01.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9775009], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec6edaea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_=plt.axvline(x=0.5, color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.74083264"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_auc=roc_auc_score(y_test, y_hat)*100\n",
    "pct_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'94.74'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:0.2f}'.format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_y_hat=[]\n",
    "for i in y_hat:\n",
    "    float_y_hat.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf=pd.DataFrame(list(zip(float_y_hat, y_test)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978763</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.732258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.907474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.950421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.848194</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.844098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.021043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.222010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.989705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.863492</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.651980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.014954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.056053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_hat  y\n",
       "0   0.054683  0\n",
       "1   0.977501  1\n",
       "2   0.656250  1\n",
       "3   0.468559  0\n",
       "4   0.978763  1\n",
       "5   0.732258  1\n",
       "6   0.907474  1\n",
       "7   0.046727  0\n",
       "8   0.950421  0\n",
       "9   0.848194  1\n",
       "10  0.844098  1\n",
       "11  0.021043  0\n",
       "12  0.014725  0\n",
       "13  0.222010  0\n",
       "14  0.989705  1\n",
       "15  0.005331  0\n",
       "16  0.863492  1\n",
       "17  0.651980  0\n",
       "18  0.014954  0\n",
       "19  0.056053  0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review with best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START a touching documentary that puts a human face on the tragedy of 9 11 by showing how one small community to honor two high school friends lost on that day the film interweaves the lives of chris and tom through interviews with family and friends and snippets of old photos through their reminiscences we glimpse two lives tragically cut short the film also documents how through a series of coincidences an inspirational memorial garden was brought forth through the efforts of many people both known and unknown to the two victims through the laughter and the tears and the sweat we see the power of hope and honor and love this films evokes many different emotions but the final feeling is one of admiration of the human spirit by tragedy'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_index[id] for id in w_x_valid[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the misclassified reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongs=ydf[(ydf.y==0)&(ydf.y_hat>0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrongs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.950421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.959358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.967919</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>0.900404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.907248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_hat  y\n",
       "8    0.950421  0\n",
       "299  0.959358  0\n",
       "558  0.967919  0\n",
       "814  0.900404  0\n",
       "955  0.907248  0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START first off i am a huge fan of tolkien and as one i will base most of my critic on his books br br the movie is a standard adventure movie well made with nifty special effects nice sound track and fine acting now if this movie was called something else than lord of the rings the reviews wouldn't be half this good as they are here br br the problem of the movie is that it takes the basic story line from tolkiens books but then it goes and hollywoods everything it can numerous scenes from the book are missing or changed quite a lot the characters are changed from the book also a thing that i think should be punishable what the movie lacks is deep insight of the characters in it i know that it is almost impossible to make a good film out of a good book and it didn't work here mostly the motivation of the characters is left hazy at best br br as a adventure movie it would rate 7 10 as a adaptation of tolkien it rates 2 10 br br i mean honestly what on earth was arwen doing at rivendell ford and as for the comments that this movie is the best ever i can only say that you are very young or you havent seen good movies br br peter jackson should have called this movie an adventure movie based on the lord of the rings\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_index[id] for id in w_x_valid[558])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=ydf[(ydf.y==1)&(ydf.y_hat<0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.063347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.080161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.098273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.091199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.088928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_hat  y\n",
       "100  0.063347  1\n",
       "333  0.080161  1\n",
       "459  0.098273  1\n",
       "466  0.091199  1\n",
       "535  0.088928  1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START a quick glance at the premise of this film would seem to indicate just another dumb '80's inbred backwood slash fest the type where sex equals death and the actors are all annoying stereotypes you actually want to die however delivers considerably more br br rather than focus on bare flesh and gore though there is a little of each no sex however the flick focuses on delivering impending dread mounting tension amidst a lovely scenic backdrop these feelings are further heightened by a cast of realistically likable characters and antagonists that are more amoral than cardboard definitions of evil oh yeah george kennedy is here too and when is that not a good thing br br if you liked wrong turn then watch this to see where much of its' methodology came from\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_index[id] for id in w_x_valid[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
