{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_NLP3_Sentiment_Oldschool.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1a_C3os_FUwVkPsBqt2qkI7O6VVQ2E-AQ",
      "authorship_tag": "ABX9TyNZ9t4WPnJFd7uKX8rwW9aQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohver/Natural_Language_Processing/blob/master/fastai3_Sentiment_Oldschool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAVNCxuevLJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "71f0016c-a36e-4291-9a4d-fcdf51823903"
      },
      "source": [
        "!pip install fastai==1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai==1.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (0.7.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (3.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (2.2.4)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (1.0.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (7.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (0.7)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (1.18.5)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0) (1.4.1)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->fastai==1.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0) (2.8.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (0.7.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (49.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai==1.0) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0) (2018.9)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==1.0) (4.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision>=0.2.1->fastai==1.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->fastai==1.0) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai==1.0) (1.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->fastai==1.0) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->fastai==1.0) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->fastai==1.0) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai==1.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBapkDSrvcwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-pYf6f2eegf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.text import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7vETn7zwXjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.utils.mem import GPUMemTrace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCxIv-JfwkxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.feature_extraction.text as sklearn_text\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s1T0niEwsnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?? URLs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP_tGhOaw0qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4a037714-08a1-4152-8d63-632fde7b0765"
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)\n",
        "path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://files.fast.ai/data/examples/imdb_sample.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.fastai/data/imdb_sample')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzI2RVsdycSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f3116b0-47ec-4497-9c7f-75883baa5842"
      },
      "source": [
        "import os\n",
        "os.listdir(path) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['texts.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCCIOyyrxT2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f0569f7b-9eaa-40be-f636-42abd240f1ac"
      },
      "source": [
        "df = pd.read_csv(path/'texts.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>is_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>This is a extremely well-made film. The acting...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>Every once in a long while a movie will come a...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>Name just says it all. I watched this movie wi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>This movie succeeds at being one of the most u...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               text  is_valid\n",
              "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
              "1  positive  This is a extremely well-made film. The acting...     False\n",
              "2  negative  Every once in a long while a movie will come a...     False\n",
              "3  positive  Name just says it all. I watched this movie wi...     False\n",
              "4  negative  This movie succeeds at being one of the most u...     False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXMCkPrKx-0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# throws `BrokenProcessPool' Error sometimes. Keep trying `till it works!\n",
        "\n",
        "count = 0\n",
        "error = True\n",
        "while error:\n",
        "  try:\n",
        "    #preprocess:\n",
        "    movie_reviews = (TextList.from_csv(path, 'texts.csv', cols = 'text').split_from_df(col = 2)\n",
        "      .label_from_df(cols = 0))\n",
        "    error = False\n",
        "    print(f'failure count is {count}\\n')\n",
        "  except: #catch all exceptions\n",
        "    # accumulate failure count\n",
        "    count = count +1\n",
        "    print(f'failure count is {count}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1x60atayFdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4DmJwvQJ00h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[0].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK3e0q5K0iZS",
        "colab_type": "text"
      },
      "source": [
        "# Examine the movie_reviews object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcXIDL0B0lyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(movie_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-bR2IVw0qM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(movie_reviews.train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMAUQ7-o00_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk5ibWwN1IPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(movie_reviews.valid))\n",
        "print(movie_reviews.valid[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "990IiPaQlSTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[3:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPHyMtBg-Jz6",
        "colab_type": "text"
      },
      "source": [
        "## Examine the structure of training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rXi3uaZ1X1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJpMXR5R-OCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.y[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotflIV2-dx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = movie_reviews.train.x[0].text\n",
        "print(f'chars: {chars}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktMxxl_l-_qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'1st review has {len(chars)} characters and {len(chars.split())} words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRvm8Br__k2u",
        "colab_type": "text"
      },
      "source": [
        "### tokens\n",
        "mapped to integers (numericalized)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wzyG6tNIByL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[3].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s59F4d0KIJeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3tRZAdV_rkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(movie_reviews.train.x[3].text, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRhx8z7sADTt",
        "colab_type": "text"
      },
      "source": [
        "# IMDB Vocabulary\n",
        "**movie_reviews object** has **.vocab property**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_9Pq63dAGXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuEIdtI4AIYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vocabs object: dictionary, tokens : their integer representation\n",
        "# 2 metods:\n",
        "# stoi (string to index) - dictionary (defaultdict)\n",
        "# itos (index to string) - list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_sTBRZUpPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test:\n",
        "print(movie_reviews.vocab.stoi['language'])\n",
        "print(movie_reviews.vocab.itos[917])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjOswPzQdzJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.stoi['blabla']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmWE5BTqgs8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.itos[movie_reviews.vocab.stoi['of']] # taki zarcik"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf1argoSTCjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.itos[1000:1010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwW9z8TmTR3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(movie_reviews.vocab.itos)\n",
        "# list, moze nie najlepszy wybor, ale ok\n",
        "# return: token z danym indexem\n",
        "# podejrzewam ze po prostu zwraca list[nr_indexu]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X22jqycAUQs2",
        "colab_type": "text"
      },
      "source": [
        "#### są uporządkowane wg frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X18kmv6UTZMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(movie_reviews.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I93-pDVuA770",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.stoi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07XLcK6pBTFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.itos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x4CimMLIs3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'itos: {len(movie_reviews.vocab.itos)}')\n",
        "print(f'stoi: {len(movie_reviews.vocab.stoi)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0pgpO8kmkZ",
        "colab_type": "text"
      },
      "source": [
        "#### defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrACLK5Gmo4i",
        "colab_type": "text"
      },
      "source": [
        "**In a defaultdict, rare words that appear fewer than three times in the corpus, and words that are not in the dictionary, are mapped to a default value, in this case, zero**  \n",
        "many words map to unknow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFqLW3IRipsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "icecream = defaultdict(lambda: 'vanilla')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zGK2GOtko1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icecream['a'] = '123'\n",
        "icecream['b'] = '456'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN2ZKCQgk99n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "icecream['bubu']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4yUO_1IlV0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.stoi['makers']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgMXxw7WmRFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.stoi['anodyne']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZf5IBlfmZMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.itos[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLqXkTWjmzOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "welcheUnknown = [word for word, num in movie_reviews.vocab.stoi.items() if num == 0]\n",
        "len(welcheUnknown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbZ51T-nT5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'len(stoi) - len(itos) = {len(movie_reviews.vocab.stoi) - len(movie_reviews.vocab.itos)}')\n",
        "print('The difference: xxunk')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhO5vXTuABh0",
        "colab_type": "text"
      },
      "source": [
        "# 3. Map the movie rewiews into the vector space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvYvUobPnru1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'number of unique tokens in the reviews: {len(movie_reviews.vocab.itos)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuCA8agDAYzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh3oh6HaBWbS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Counter\n",
        "A **Counter** is a useful Python object.  A **Counter** applied to a list returns an ordered dictionary whose keys are the unique elements in the list, and whose values are the counts of the unique elements. Counters are from the collections module (along with OrderedDict, defaultdict, deque, and namedtuple).\n",
        "Here is how Counters work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnIbu_ZWBc5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parametr: reviewIndex - index of review in dataset (one of the 800 data)\n",
        "TokenCounter = lambda reviewIndex: Counter(movie_reviews.train.x[reviewIndex].data)\n",
        "TokenCounter(0).items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-M2lEYVB21J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train.x[456].data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ai_SgK-mmj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TokenCounter(546).items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56DikZDFCOm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Review #33:\n",
        "len(TokenCounter(33))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjvmZHBnRRFE",
        "colab_type": "text"
      },
      "source": [
        "Convert a matrix to CSR format (Compressed Sparse Row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpa5hgF3ZJOU",
        "colab_type": "text"
      },
      "source": [
        "## BIG O:\n",
        "Convertions between CSR & CSC are linear time operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHHRM9ZsRRbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# document-term matrix in CSR format\n",
        "# return (values, columnIndices, rowPointer)\n",
        "\n",
        "def get_doc_term_matrix(text_list, n_terms):\n",
        "  '''\n",
        "  input: text_list: a TextList object\n",
        "  n_terms: the number of tokens in IMDB vocabulary\n",
        "\n",
        "  output: \n",
        "  CSR format sparse representation of the document-term matrix, \n",
        "  as scipy.sparse.csr_matrix object\n",
        "  '''\n",
        "\n",
        "  # initialize arrays\n",
        "  values = []\n",
        "  column_indices = []\n",
        "  row_pointer = []\n",
        "  row_pointer.append(0)\n",
        "\n",
        "  # from the TextListObject:\n",
        "  for _, doc in enumerate (text_list):\n",
        "    feature_counter = Counter(doc.data) # .data: list of token-indices in the revies (patrz wyżej, TextList object)\n",
        "      # movie_reviews.train.x[3].data\n",
        "    column_indices.extend(feature_counter.keys())\n",
        "    values.extend(feature_counter.values())\n",
        "    # tack on N (number of nonzero elements in the matrix) to the end of the row_pointer array\n",
        "    row_pointer.append(len(values))\n",
        "\n",
        "  return scipy.sparse.csr_matrix((values, column_indices, row_pointer),\n",
        "                                 shape = (len(row_pointer) -1, n_terms),\n",
        "                                 dtype = int\n",
        "                                 )\n",
        "\n",
        "# czyli podajemy do SciPi w formacie COO, on konwertuje dalej\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3tfHUgbGpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIU8lJc28Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train_doc_term = get_doc_term_matrix(movie_reviews.train.x, len(movie_reviews.vocab.itos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88gdpt5Q2_mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(train_doc_term))\n",
        "train_doc_term.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qToIHgLDlyN",
        "colab_type": "text"
      },
      "source": [
        "# Embedding "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlGNFT0D2vD",
        "colab_type": "text"
      },
      "source": [
        "#### Make a `count_vectorizer` function that represents a movie review as a 6008-dimensional `embedding vector`\n",
        "#### The `indices` of  the `embedding vector` correspond to the n6008 numericalized tokens in the vocabulary; the `values` specify how often the corresponding token appears in the review. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV3ns7igC9zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nTerms = len(movie_reviews.vocab.itos)\n",
        "nDocs = len(movie_reviews.train.x)\n",
        "makeTokenCounter = lambda reviewIndex: Counter(movie_reviews.train.x[reviewIndex].data)\n",
        "\n",
        "def countVectorizer(reviewIndex, nTerms = nTerms, nmakeTokenCounter = makeTokenCounter):\n",
        "  '''\n",
        "  input: review index, nTerms, tokenizer function\n",
        "  output: embeding vector for the review\n",
        "  '''\n",
        "  embeddingVector = np.zeros(nTerms)\n",
        "  keys = list(makeTokenCounter(reviewIndex).keys())\n",
        "  values = list(makeTokenCounter(reviewIndex).values())\n",
        "  embeddingVector[keys] = values\n",
        "  return embeddingVector\n",
        "\n",
        "# embedding vector for the 1st review:\n",
        "embeddingVector = countVectorizer(0)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9G5ZBPvDROG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'the review is embedded in {len(embeddingVector)} dimensional vector')\n",
        "embeddingVector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGS1dU-lGWX-",
        "colab_type": "text"
      },
      "source": [
        "# 4. Create the document-term matrix for the IMDb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qERig4o9Gct1",
        "colab_type": "text"
      },
      "source": [
        "#### In non-deep learning methods of NLP, we are often interested only in `which words` were used in a review, and `how often each word got used`. This is known as the `bag of words` approach, and it suggests a really simple way to store a document (in this case, a movie review). \n",
        "\n",
        "#### For each review we can keep track of which words were used and how often each word was used with a `vector` whose `length` is the number of tokens in the vocabulary, which we will call `n`. The `indexes` of this `vector` correspond to the `tokens` in the `IMDb vocabulary`, and the`values` of the vector are the number of times the corresponding tokens appeared in the review. For example the values stored at indexes 0, 1, 2, 3, 4 of the vector record the number of times the 5 tokens ['xxunk','xxpad','xxbos','xxeos','xxfld'] appeared in the review, respectively.\n",
        "\n",
        "#### Now, if our movie review database has `m` reviews, and each review is represented by a `vector` of length `n`, then vertically stacking the row vectors for all the reviews creates a matrix representation of the IMDb, which we call its `document-term matrix`. The `rows` correspond to `documents` (reviews), while the `columns` correspond to `terms` (or tokens in the vocabulary)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1iSc5smGg5D",
        "colab_type": "text"
      },
      "source": [
        "In the previous lesson, we used [sklearn's CountVectorizer](https://github.com/scikit-learn/scikit-learn/blob/55bf5d9/sklearn/feature_extraction/text.py#L940) to generate the `vectors` that represent individual reviews. Today we will create our own (similar) version.  This is for two reasons:\n",
        "- to understand what sklearn is doing underneath the hood\n",
        "- to create something that will work with a fastai TextList"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fnqlAZjGMHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_reviews.vocab.itos[1568]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10x_8Vq_Hpvs",
        "colab_type": "text"
      },
      "source": [
        "### Form the embedding vectors for the movie_reviews in the training set and stack them vertically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZZiNMuTHY1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build the full document-term matrix\n",
        "print(f'There are {nDocs} reviews and {nTerms} unique tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj9--vw8IKk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a function to build the full document-term matrix\n",
        "print(f'there are {nDocs} reviews, and {nTerms} unique tokens in the vocabulary')\n",
        "def make_full_doc_term_matrix(countVectorizer,n_terms=nTerms,n_docs=nDocs):\n",
        "    \n",
        "    # loop through the movie reviews\n",
        "    for doc_index in range(nDocs):\n",
        "        \n",
        "        # make the embedding vector for the current review\n",
        "        embedding_vector = countVectorizer(doc_index,nTerms)    \n",
        "            \n",
        "        # append the embedding vector to the document-term matrix\n",
        "        if(doc_index == 0):\n",
        "            A = embedding_vector\n",
        "        else:\n",
        "            A = np.vstack((A,embedding_vector))\n",
        "            \n",
        "    # return the document-term matrix\n",
        "    return A\n",
        "\n",
        "# Build the full document term matrix for the movie_reviews training set\n",
        "A = make_full_doc_term_matrix(countVectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A27bcQuJJ1GM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuSIDBtbKn_y",
        "colab_type": "text"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_f8Zk9sKoLh",
        "colab_type": "text"
      },
      "source": [
        "### Explore the `sparsity` of the document-term matrix\n",
        "The sparsity of a matrix is defined as the fraction of of zero-valued elements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1FHHYQkJ-cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NNZ = np.count_nonzero(A)\n",
        "sparsity = (A.size-NNZ)/A.size\n",
        "print(f'Only {NNZ} of the {A.size} elements in the document-term matrix are nonzero')\n",
        "print(f'The sparsity of the document-term matrix is {sparsity}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXcfDuZELHl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.spy(A, markersize=.10, aspect='auto')\n",
        "fig.set_size_inches(8,6)\n",
        "fig.savefig('doc_term_matrix.png', dpi = 800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeD-Cg-iMdwn",
        "colab_type": "text"
      },
      "source": [
        "#### Several observations stand out:\n",
        "1. Evidently, the document-term matrix is `sparse` ie. has a high proportion of zeros! \n",
        "2. The density of the matrix increases toward the `left` edge. This makes sense because the tokens are ordered by usage frequency, with frequency increasing toward the `left`.\n",
        "3. There is a perplexing pattern of curved vertical `density ripples`. If anyone has an explanation, please let me know! \n",
        "\n",
        "#### Next we'll see how to  exploit matrix sparsity to save memory storage space, and compute time and resources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pClOro_PMWa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txrZRyNf0Anq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}