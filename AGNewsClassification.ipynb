{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AGNewsClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AvctocoumWCzDj9msCmsaoxgnhV6FQ6A",
      "authorship_tag": "ABX9TyMbJKByW++p6D+TEkXZpoFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tohver/Natural_Language_Processing/blob/master/AGNewsClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KciMYFnN-dG1"
      },
      "source": [
        "!pip install flair\r\n",
        "!pip install sentence-transformers\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import flair\r\n",
        "from flair.data import Sentence\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from pathlib import Path\r\n",
        "import seaborn as sns\r\n",
        "from flair.datasets import ClassificationCorpus, CSVClassificationCorpus\r\n",
        "from flair.data import Corpus\r\n",
        "from flair.embeddings import StackedEmbeddings, FlairEmbeddings, WordEmbeddings, DocumentRNNEmbeddings, DocumentLSTMEmbeddings, TransformerWordEmbeddings, SentenceTransformerDocumentEmbeddings\r\n",
        "from flair.data import Sentence\r\n",
        "from flair.models import TextClassifier\r\n",
        "from flair.trainers import ModelTrainer\r\n",
        "from torch.optim.adam import Adam\r\n",
        "\r\n",
        "path = Path('/content/drive/MyDrive/Colab Notebooks/data/AG_News')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "p-V92DCwmHhR",
        "outputId": "14ba5ce4-60ef-4f95-e6dd-79b83eb4c774"
      },
      "source": [
        "news = pd.read_csv(path/'train_raw.csv', header = None)\r\n",
        "news.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  ...                                                  2\n",
              "0  3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
              "1  3  ...  Reuters - Private investment firm Carlyle Grou...\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LIfuVDxSRbo",
        "outputId": "b9bd7312-784d-46f4-a056-0cffde2bc64f"
      },
      "source": [
        "for i in range(10):\n",
        "  print(f'{news.iloc[i,1]}\\n{news.iloc[i,2]}\\n')\n",
        "news['text'] = news[1] + ' ' + news[2]\n",
        "news.columns = ['labels', 't1', 't2', 'text']\n",
        "newsDf = news[['labels', 'text']]\n",
        "newsDf.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wall St. Bears Claw Back Into the Black (Reuters)\n",
            "Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
            "\n",
            "Carlyle Looks Toward Commercial Aerospace (Reuters)\n",
            "Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
            "\n",
            "Oil and Economy Cloud Stocks' Outlook (Reuters)\n",
            "Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are expected to\\hang over the stock market next week during the depth of the\\summer doldrums.\n",
            "\n",
            "Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)\n",
            "Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\intelligence showed a rebel militia could strike\\infrastructure, an oil official said on Saturday.\n",
            "\n",
            "Oil prices soar to all-time record, posing new menace to US economy (AFP)\n",
            "AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.\n",
            "\n",
            "Stocks End Up, But Near Year Lows (Reuters)\n",
            "Reuters - Stocks ended slightly higher on Friday\\but stayed near lows for the year as oil prices surged past  #36;46\\a barrel, offsetting a positive outlook from computer maker\\Dell Inc. (DELL.O)\n",
            "\n",
            "Money Funds Fell in Latest Week (AP)\n",
            "AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\n",
            "\n",
            "Fed minutes show dissent over inflation (USATODAY.com)\n",
            "USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\n",
            "\n",
            "Safety Net (Forbes.com)\n",
            "Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.\n",
            "\n",
            "Wall St. Bears Claw Back Into the Black\n",
            " NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "inHJiA56uNdM",
        "outputId": "d961cd90-966b-459e-95c5-973e59e2af2c"
      },
      "source": [
        "newsDf.head(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels                                               text\n",
              "0       3  Wall St. Bears Claw Back Into the Black (Reute...\n",
              "1       3  Carlyle Looks Toward Commercial Aerospace (Reu..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1_VzOWqYYaZ"
      },
      "source": [
        "test = pd.read_csv(path/'test_raw.csv', header = None)\r\n",
        "test['text'] = test[1] + ' ' + test[2]\r\n",
        "test.columns = ['labels', 't1', 't2', 'text']\r\n",
        "test = test[['labels', 'text']]\r\n",
        "test.to_csv(path/'test.csv', header = None)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_7HBcZbYYKM"
      },
      "source": [
        "train, val = train_test_split(newsDf, test_size = .05, random_state = 0, stratify = newsDf['labels'])\r\n",
        "train.to_csv(path/'train.csv', header = None)\r\n",
        "val.to_csv(path/'dev.csv', header = None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLfEkxi0YX0q",
        "outputId": "18893a76-3a75-42e9-b84c-de29f0acee47"
      },
      "source": [
        "print(f'train set: {train.labels.value_counts()}\\n')\r\n",
        "print(f'test set: {test.labels.value_counts()}\\n')\r\n",
        "print(f'val set: {val.labels.value_counts()}\\n')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set: 4    28500\n",
            "3    28500\n",
            "2    28500\n",
            "1    28500\n",
            "Name: labels, dtype: int64\n",
            "\n",
            "test set: 3    1900\n",
            "2    1900\n",
            "1    1900\n",
            "4    1900\n",
            "Name: labels, dtype: int64\n",
            "\n",
            "val set: 3    1500\n",
            "2    1500\n",
            "1    1500\n",
            "4    1500\n",
            "Name: labels, dtype: int64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5feIU7XluNS9",
        "outputId": "9e2b7d3f-386f-4e34-93b1-be2219ed46cc"
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100830</th>\n",
              "      <td>3</td>\n",
              "      <td>P2P Music Upstart Signs On the Big Boys A new ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65783</th>\n",
              "      <td>1</td>\n",
              "      <td>US must wait to prosecute Muslim cleric LONDON...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4250</th>\n",
              "      <td>4</td>\n",
              "      <td>OSDL introduces improved Linux kernel developm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70666</th>\n",
              "      <td>3</td>\n",
              "      <td>Bangalore Thrives, Chokes on Outsourcing  BANG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60099</th>\n",
              "      <td>4</td>\n",
              "      <td>With Help, Sea Turtles Rally to Escape Oblivio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        labels                                               text\n",
              "100830       3  P2P Music Upstart Signs On the Big Boys A new ...\n",
              "65783        1  US must wait to prosecute Muslim cleric LONDON...\n",
              "4250         4  OSDL introduces improved Linux kernel developm...\n",
              "70666        3  Bangalore Thrives, Chokes on Outsourcing  BANG...\n",
              "60099        4  With Help, Sea Turtles Rally to Escape Oblivio..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "7g5OCGS6HX34",
        "outputId": "9582b131-368b-45a1-c530-47b0e7d259a8"
      },
      "source": [
        "sns.countplot(train['labels'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f068c31c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPjJdFsSx8kR",
        "outputId": "b590a46d-6c51-4111-a2ac-d7f6099d8850"
      },
      "source": [
        "columnNameMap = {1 : 'label_topic', 2 : 'text'}\r\n",
        "corpus: Corpus = CSVClassificationCorpus(path, column_name_map = columnNameMap)\r\n",
        "label_dict = corpus.make_label_dictionary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-18 23:28:26,202 Reading data from /content/drive/MyDrive/Colab Notebooks/data/AG_News\n",
            "2021-02-18 23:28:26,203 Train: /content/drive/MyDrive/Colab Notebooks/data/AG_News/train.csv\n",
            "2021-02-18 23:28:26,203 Dev: /content/drive/MyDrive/Colab Notebooks/data/AG_News/dev.csv\n",
            "2021-02-18 23:28:26,207 Test: /content/drive/MyDrive/Colab Notebooks/data/AG_News/test.csv\n",
            "2021-02-18 23:28:26,825 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 121600/121600 [02:10<00:00, 929.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-18 23:30:37,739 [b'2', b'4', b'3', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBZsa-_X0crO",
        "outputId": "dce1df42-83c4-4903-e052-9e02f18d1469"
      },
      "source": [
        "document_transformer_embeddings = SentenceTransformerDocumentEmbeddings('bert-base-nli-mean-tokens')\r\n",
        "classifier = TextClassifier(document_transformer_embeddings, label_dictionary=label_dict)\r\n",
        "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:14<00:00, 28.0MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywVpVemH1aE1",
        "outputId": "d35128e9-9654-4e58-a8d5-1e8335708707"
      },
      "source": [
        "trainer.train(path/'models/', learning_rate=3e-5, max_epochs = 10, patience=2, checkpoint = True, mini_batch_size = 16, mini_batch_chunk_size = 4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-18 23:31:14,658 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,662 Model: \"TextClassifier(\n",
            "  (document_embeddings): SentenceTransformerDocumentEmbeddings(\n",
            "    (model): SentenceTransformer(\n",
            "      (0): Transformer(\n",
            "        (auto_model): BertModel(\n",
            "          (embeddings): BertEmbeddings(\n",
            "            (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "            (position_embeddings): Embedding(512, 768)\n",
            "            (token_type_embeddings): Embedding(2, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Pooling()\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=768, out_features=4, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-02-18 23:31:14,663 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,664 Corpus: \"Corpus: 114000 train + 6000 dev + 7600 test sentences\"\n",
            "2021-02-18 23:31:14,665 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,666 Parameters:\n",
            "2021-02-18 23:31:14,667  - learning_rate: \"3e-05\"\n",
            "2021-02-18 23:31:14,668  - mini_batch_size: \"16\"\n",
            "2021-02-18 23:31:14,670  - patience: \"2\"\n",
            "2021-02-18 23:31:14,675  - anneal_factor: \"0.5\"\n",
            "2021-02-18 23:31:14,676  - max_epochs: \"10\"\n",
            "2021-02-18 23:31:14,677  - shuffle: \"True\"\n",
            "2021-02-18 23:31:14,679  - train_with_dev: \"False\"\n",
            "2021-02-18 23:31:14,680  - batch_growth_annealing: \"False\"\n",
            "2021-02-18 23:31:14,681 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,683 Model training base path: \"/content/drive/MyDrive/Colab Notebooks/data/AG_News/models\"\n",
            "2021-02-18 23:31:14,684 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,685 Device: cuda:0\n",
            "2021-02-18 23:31:14,687 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:31:14,698 Embeddings storage mode: cpu\n",
            "2021-02-18 23:31:14,713 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-18 23:34:21,225 epoch 1 - iter 712/7125 - loss 1.21692016 - samples/sec: 62.50 - lr: 0.000030\n",
            "2021-02-18 23:37:25,243 epoch 1 - iter 1424/7125 - loss 1.02444236 - samples/sec: 63.12 - lr: 0.000030\n",
            "2021-02-18 23:40:26,687 epoch 1 - iter 2136/7125 - loss 0.90621774 - samples/sec: 64.01 - lr: 0.000030\n",
            "2021-02-18 23:43:28,281 epoch 1 - iter 2848/7125 - loss 0.82817981 - samples/sec: 64.03 - lr: 0.000030\n",
            "2021-02-18 23:46:29,567 epoch 1 - iter 3560/7125 - loss 0.76575838 - samples/sec: 64.06 - lr: 0.000030\n",
            "2021-02-18 23:49:31,355 epoch 1 - iter 4272/7125 - loss 0.71941520 - samples/sec: 63.97 - lr: 0.000030\n",
            "2021-02-18 23:52:32,835 epoch 1 - iter 4984/7125 - loss 0.68214079 - samples/sec: 64.01 - lr: 0.000030\n",
            "2021-02-18 23:55:33,850 epoch 1 - iter 5696/7125 - loss 0.65497651 - samples/sec: 64.16 - lr: 0.000030\n",
            "2021-02-18 23:58:35,240 epoch 1 - iter 6408/7125 - loss 0.63085310 - samples/sec: 64.11 - lr: 0.000030\n",
            "2021-02-19 00:01:37,345 epoch 1 - iter 7120/7125 - loss 0.60845781 - samples/sec: 63.78 - lr: 0.000030\n",
            "2021-02-19 00:01:38,745 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 00:01:38,746 EPOCH 1 done: loss 0.6083 - lr 0.0000300\n",
            "2021-02-19 00:03:17,282 DEV : loss 0.4104565382003784 - score 0.8677\n",
            "2021-02-19 00:03:23,782 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 00:03:27,415 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 00:06:34,843 epoch 2 - iter 712/7125 - loss 0.43062990 - samples/sec: 62.03 - lr: 0.000030\n",
            "2021-02-19 00:09:37,953 epoch 2 - iter 1424/7125 - loss 0.41821090 - samples/sec: 63.32 - lr: 0.000030\n",
            "2021-02-19 00:12:40,893 epoch 2 - iter 2136/7125 - loss 0.42130436 - samples/sec: 63.38 - lr: 0.000030\n",
            "2021-02-19 00:15:45,812 epoch 2 - iter 2848/7125 - loss 0.41034384 - samples/sec: 62.72 - lr: 0.000030\n",
            "2021-02-19 00:18:50,921 epoch 2 - iter 3560/7125 - loss 0.40351724 - samples/sec: 62.73 - lr: 0.000030\n",
            "2021-02-19 00:21:56,434 epoch 2 - iter 4272/7125 - loss 0.39923879 - samples/sec: 62.52 - lr: 0.000030\n",
            "2021-02-19 00:25:01,693 epoch 2 - iter 4984/7125 - loss 0.39642813 - samples/sec: 62.67 - lr: 0.000030\n",
            "2021-02-19 00:28:04,204 epoch 2 - iter 5696/7125 - loss 0.39755062 - samples/sec: 63.53 - lr: 0.000030\n",
            "2021-02-19 00:31:07,369 epoch 2 - iter 6408/7125 - loss 0.39729240 - samples/sec: 63.29 - lr: 0.000030\n",
            "2021-02-19 00:34:13,087 epoch 2 - iter 7120/7125 - loss 0.39398533 - samples/sec: 62.53 - lr: 0.000030\n",
            "2021-02-19 00:34:14,499 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 00:34:14,500 EPOCH 2 done: loss 0.3938 - lr 0.0000300\n",
            "2021-02-19 00:35:57,413 DEV : loss 0.36020976305007935 - score 0.8813\n",
            "2021-02-19 00:36:04,014 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 00:36:07,927 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 00:39:19,199 epoch 3 - iter 712/7125 - loss 0.36610644 - samples/sec: 60.75 - lr: 0.000030\n",
            "2021-02-19 00:42:30,105 epoch 3 - iter 1424/7125 - loss 0.38778842 - samples/sec: 60.80 - lr: 0.000030\n",
            "2021-02-19 00:45:39,936 epoch 3 - iter 2136/7125 - loss 0.38037804 - samples/sec: 61.08 - lr: 0.000030\n",
            "2021-02-19 00:48:46,285 epoch 3 - iter 2848/7125 - loss 0.37789658 - samples/sec: 62.31 - lr: 0.000030\n",
            "2021-02-19 00:51:50,307 epoch 3 - iter 3560/7125 - loss 0.37851344 - samples/sec: 63.02 - lr: 0.000030\n",
            "2021-02-19 00:54:55,381 epoch 3 - iter 4272/7125 - loss 0.37130030 - samples/sec: 62.66 - lr: 0.000030\n",
            "2021-02-19 00:58:02,788 epoch 3 - iter 4984/7125 - loss 0.36923862 - samples/sec: 61.96 - lr: 0.000030\n",
            "2021-02-19 01:01:09,545 epoch 3 - iter 5696/7125 - loss 0.36689304 - samples/sec: 62.11 - lr: 0.000030\n",
            "2021-02-19 01:04:16,150 epoch 3 - iter 6408/7125 - loss 0.36835441 - samples/sec: 62.28 - lr: 0.000030\n",
            "2021-02-19 01:07:22,802 epoch 3 - iter 7120/7125 - loss 0.36669556 - samples/sec: 62.15 - lr: 0.000030\n",
            "2021-02-19 01:07:24,213 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 01:07:24,215 EPOCH 3 done: loss 0.3667 - lr 0.0000300\n",
            "2021-02-19 01:09:05,352 DEV : loss 0.3414340019226074 - score 0.8828\n",
            "2021-02-19 01:09:11,937 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 01:09:15,851 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 01:12:22,898 epoch 4 - iter 712/7125 - loss 0.35951467 - samples/sec: 62.16 - lr: 0.000030\n",
            "2021-02-19 01:15:25,352 epoch 4 - iter 1424/7125 - loss 0.36778293 - samples/sec: 63.56 - lr: 0.000030\n",
            "2021-02-19 01:18:28,464 epoch 4 - iter 2136/7125 - loss 0.36114047 - samples/sec: 63.39 - lr: 0.000030\n",
            "2021-02-19 01:21:33,007 epoch 4 - iter 2848/7125 - loss 0.35572929 - samples/sec: 62.85 - lr: 0.000030\n",
            "2021-02-19 01:24:36,529 epoch 4 - iter 3560/7125 - loss 0.35198537 - samples/sec: 63.19 - lr: 0.000030\n",
            "2021-02-19 01:27:39,973 epoch 4 - iter 4272/7125 - loss 0.35298796 - samples/sec: 63.29 - lr: 0.000030\n",
            "2021-02-19 01:30:43,230 epoch 4 - iter 4984/7125 - loss 0.35225427 - samples/sec: 63.28 - lr: 0.000030\n",
            "2021-02-19 01:33:46,379 epoch 4 - iter 5696/7125 - loss 0.35513700 - samples/sec: 63.33 - lr: 0.000030\n",
            "2021-02-19 01:36:50,521 epoch 4 - iter 6408/7125 - loss 0.35449555 - samples/sec: 63.03 - lr: 0.000030\n",
            "2021-02-19 01:39:54,420 epoch 4 - iter 7120/7125 - loss 0.35422131 - samples/sec: 63.06 - lr: 0.000030\n",
            "2021-02-19 01:39:55,811 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 01:39:55,814 EPOCH 4 done: loss 0.3541 - lr 0.0000300\n",
            "2021-02-19 01:41:37,060 DEV : loss 0.330353319644928 - score 0.8857\n",
            "2021-02-19 01:41:43,622 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 01:41:47,490 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 01:44:55,631 epoch 5 - iter 712/7125 - loss 0.34687464 - samples/sec: 61.80 - lr: 0.000030\n",
            "2021-02-19 01:47:59,958 epoch 5 - iter 1424/7125 - loss 0.35626539 - samples/sec: 62.90 - lr: 0.000030\n",
            "2021-02-19 01:51:03,739 epoch 5 - iter 2136/7125 - loss 0.34985408 - samples/sec: 63.10 - lr: 0.000030\n",
            "2021-02-19 01:54:08,532 epoch 5 - iter 2848/7125 - loss 0.34255774 - samples/sec: 62.81 - lr: 0.000030\n",
            "2021-02-19 01:57:11,867 epoch 5 - iter 3560/7125 - loss 0.33884125 - samples/sec: 63.25 - lr: 0.000030\n",
            "2021-02-19 02:00:15,624 epoch 5 - iter 4272/7125 - loss 0.33287336 - samples/sec: 63.17 - lr: 0.000030\n",
            "2021-02-19 02:03:21,251 epoch 5 - iter 4984/7125 - loss 0.33296118 - samples/sec: 62.47 - lr: 0.000030\n",
            "2021-02-19 02:06:26,148 epoch 5 - iter 5696/7125 - loss 0.33308968 - samples/sec: 62.78 - lr: 0.000030\n",
            "2021-02-19 02:09:31,769 epoch 5 - iter 6408/7125 - loss 0.33184463 - samples/sec: 62.48 - lr: 0.000030\n",
            "2021-02-19 02:12:37,463 epoch 5 - iter 7120/7125 - loss 0.33277388 - samples/sec: 62.45 - lr: 0.000030\n",
            "2021-02-19 02:12:39,076 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 02:12:39,076 EPOCH 5 done: loss 0.3328 - lr 0.0000300\n",
            "2021-02-19 02:14:20,505 DEV : loss 0.32371780276298523 - score 0.8873\n",
            "2021-02-19 02:14:27,220 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 02:14:31,431 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 02:17:38,060 epoch 6 - iter 712/7125 - loss 0.34717447 - samples/sec: 62.27 - lr: 0.000030\n",
            "2021-02-19 02:20:43,642 epoch 6 - iter 1424/7125 - loss 0.35685902 - samples/sec: 62.55 - lr: 0.000030\n",
            "2021-02-19 02:23:47,886 epoch 6 - iter 2136/7125 - loss 0.35233767 - samples/sec: 62.93 - lr: 0.000030\n",
            "2021-02-19 02:26:53,025 epoch 6 - iter 2848/7125 - loss 0.34612245 - samples/sec: 62.70 - lr: 0.000030\n",
            "2021-02-19 02:29:58,128 epoch 6 - iter 3560/7125 - loss 0.34698400 - samples/sec: 62.64 - lr: 0.000030\n",
            "2021-02-19 02:33:02,133 epoch 6 - iter 4272/7125 - loss 0.34516539 - samples/sec: 63.03 - lr: 0.000030\n",
            "2021-02-19 02:36:07,383 epoch 6 - iter 4984/7125 - loss 0.34234800 - samples/sec: 62.67 - lr: 0.000030\n",
            "2021-02-19 02:39:11,926 epoch 6 - iter 5696/7125 - loss 0.33914926 - samples/sec: 62.82 - lr: 0.000030\n",
            "2021-02-19 02:42:15,635 epoch 6 - iter 6408/7125 - loss 0.33657027 - samples/sec: 63.11 - lr: 0.000030\n",
            "2021-02-19 02:45:20,609 epoch 6 - iter 7120/7125 - loss 0.33545332 - samples/sec: 62.76 - lr: 0.000030\n",
            "2021-02-19 02:45:21,999 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 02:45:22,000 EPOCH 6 done: loss 0.3354 - lr 0.0000300\n",
            "2021-02-19 02:47:02,670 DEV : loss 0.3182004690170288 - score 0.888\n",
            "2021-02-19 02:47:09,189 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 02:47:13,112 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 02:50:20,942 epoch 7 - iter 712/7125 - loss 0.35352786 - samples/sec: 61.93 - lr: 0.000030\n",
            "2021-02-19 02:53:25,748 epoch 7 - iter 1424/7125 - loss 0.33356154 - samples/sec: 62.75 - lr: 0.000030\n",
            "2021-02-19 02:56:30,464 epoch 7 - iter 2136/7125 - loss 0.33391120 - samples/sec: 62.77 - lr: 0.000030\n",
            "2021-02-19 02:59:36,038 epoch 7 - iter 2848/7125 - loss 0.33107355 - samples/sec: 62.55 - lr: 0.000030\n",
            "2021-02-19 03:02:41,699 epoch 7 - iter 3560/7125 - loss 0.32847580 - samples/sec: 62.46 - lr: 0.000030\n",
            "2021-02-19 03:05:49,122 epoch 7 - iter 4272/7125 - loss 0.32796325 - samples/sec: 61.93 - lr: 0.000030\n",
            "2021-02-19 03:08:58,827 epoch 7 - iter 4984/7125 - loss 0.32659973 - samples/sec: 61.12 - lr: 0.000030\n",
            "2021-02-19 03:12:05,386 epoch 7 - iter 5696/7125 - loss 0.32615562 - samples/sec: 62.17 - lr: 0.000030\n",
            "2021-02-19 03:15:15,292 epoch 7 - iter 6408/7125 - loss 0.32425363 - samples/sec: 61.13 - lr: 0.000030\n",
            "2021-02-19 03:18:27,378 epoch 7 - iter 7120/7125 - loss 0.32273503 - samples/sec: 60.35 - lr: 0.000030\n",
            "2021-02-19 03:18:28,803 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 03:18:28,804 EPOCH 7 done: loss 0.3227 - lr 0.0000300\n",
            "2021-02-19 03:20:12,575 DEV : loss 0.3148873448371887 - score 0.8887\n",
            "2021-02-19 03:20:19,247 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 03:20:23,233 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 03:23:35,218 epoch 8 - iter 712/7125 - loss 0.34613002 - samples/sec: 60.59 - lr: 0.000030\n",
            "2021-02-19 03:26:45,225 epoch 8 - iter 1424/7125 - loss 0.33515077 - samples/sec: 61.03 - lr: 0.000030\n",
            "2021-02-19 03:29:57,425 epoch 8 - iter 2136/7125 - loss 0.33064595 - samples/sec: 60.33 - lr: 0.000030\n",
            "2021-02-19 03:33:08,217 epoch 8 - iter 2848/7125 - loss 0.32597783 - samples/sec: 60.84 - lr: 0.000030\n",
            "2021-02-19 03:36:15,129 epoch 8 - iter 3560/7125 - loss 0.32715824 - samples/sec: 62.05 - lr: 0.000030\n",
            "2021-02-19 03:39:25,600 epoch 8 - iter 4272/7125 - loss 0.32640513 - samples/sec: 60.96 - lr: 0.000030\n",
            "2021-02-19 03:42:33,240 epoch 8 - iter 4984/7125 - loss 0.32875310 - samples/sec: 61.80 - lr: 0.000030\n",
            "2021-02-19 03:45:40,069 epoch 8 - iter 5696/7125 - loss 0.32659850 - samples/sec: 62.16 - lr: 0.000030\n",
            "2021-02-19 03:48:51,360 epoch 8 - iter 6408/7125 - loss 0.32443146 - samples/sec: 60.62 - lr: 0.000030\n",
            "2021-02-19 03:52:03,127 epoch 8 - iter 7120/7125 - loss 0.32584729 - samples/sec: 60.47 - lr: 0.000030\n",
            "2021-02-19 03:52:04,590 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 03:52:04,592 EPOCH 8 done: loss 0.3258 - lr 0.0000300\n",
            "2021-02-19 03:53:50,303 DEV : loss 0.312004953622818 - score 0.8882\n",
            "2021-02-19 03:53:57,324 BAD EPOCHS (no improvement): 1\n",
            "2021-02-19 03:53:59,333 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 03:57:16,093 epoch 9 - iter 712/7125 - loss 0.32122067 - samples/sec: 59.04 - lr: 0.000030\n",
            "2021-02-19 04:00:29,529 epoch 9 - iter 1424/7125 - loss 0.32780039 - samples/sec: 60.03 - lr: 0.000030\n",
            "2021-02-19 04:03:41,961 epoch 9 - iter 2136/7125 - loss 0.32958839 - samples/sec: 60.26 - lr: 0.000030\n",
            "2021-02-19 04:06:53,969 epoch 9 - iter 2848/7125 - loss 0.32265569 - samples/sec: 60.47 - lr: 0.000030\n",
            "2021-02-19 04:10:06,118 epoch 9 - iter 3560/7125 - loss 0.32639286 - samples/sec: 60.35 - lr: 0.000030\n",
            "2021-02-19 04:13:15,590 epoch 9 - iter 4272/7125 - loss 0.32341639 - samples/sec: 61.20 - lr: 0.000030\n",
            "2021-02-19 04:16:22,595 epoch 9 - iter 4984/7125 - loss 0.32321536 - samples/sec: 62.02 - lr: 0.000030\n",
            "2021-02-19 04:19:28,951 epoch 9 - iter 5696/7125 - loss 0.32294719 - samples/sec: 62.28 - lr: 0.000030\n",
            "2021-02-19 04:22:33,650 epoch 9 - iter 6408/7125 - loss 0.32353570 - samples/sec: 62.79 - lr: 0.000030\n",
            "2021-02-19 04:25:37,880 epoch 9 - iter 7120/7125 - loss 0.32159995 - samples/sec: 62.95 - lr: 0.000030\n",
            "2021-02-19 04:25:39,298 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 04:25:39,301 EPOCH 9 done: loss 0.3215 - lr 0.0000300\n",
            "2021-02-19 04:27:19,836 DEV : loss 0.30851998925209045 - score 0.8913\n",
            "2021-02-19 04:27:26,633 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2021-02-19 04:27:30,610 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 04:30:38,420 epoch 10 - iter 712/7125 - loss 0.29803536 - samples/sec: 61.87 - lr: 0.000030\n",
            "2021-02-19 04:33:42,670 epoch 10 - iter 1424/7125 - loss 0.29649074 - samples/sec: 62.94 - lr: 0.000030\n",
            "2021-02-19 04:36:47,863 epoch 10 - iter 2136/7125 - loss 0.30408668 - samples/sec: 62.68 - lr: 0.000030\n",
            "2021-02-19 04:39:52,373 epoch 10 - iter 2848/7125 - loss 0.31103980 - samples/sec: 62.85 - lr: 0.000030\n",
            "2021-02-19 04:42:57,066 epoch 10 - iter 3560/7125 - loss 0.31340373 - samples/sec: 62.85 - lr: 0.000030\n",
            "2021-02-19 04:46:02,574 epoch 10 - iter 4272/7125 - loss 0.31569431 - samples/sec: 62.53 - lr: 0.000030\n",
            "2021-02-19 04:49:09,042 epoch 10 - iter 4984/7125 - loss 0.31612238 - samples/sec: 62.20 - lr: 0.000030\n",
            "2021-02-19 04:52:15,263 epoch 10 - iter 5696/7125 - loss 0.31604207 - samples/sec: 62.34 - lr: 0.000030\n",
            "2021-02-19 04:55:23,533 epoch 10 - iter 6408/7125 - loss 0.31829284 - samples/sec: 61.60 - lr: 0.000030\n",
            "2021-02-19 04:58:32,878 epoch 10 - iter 7120/7125 - loss 0.31870193 - samples/sec: 61.31 - lr: 0.000030\n",
            "2021-02-19 04:58:34,355 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 04:58:34,356 EPOCH 10 done: loss 0.3186 - lr 0.0000300\n",
            "2021-02-19 05:00:18,842 DEV : loss 0.30598127841949463 - score 0.89\n",
            "2021-02-19 05:00:25,526 BAD EPOCHS (no improvement): 1\n",
            "2021-02-19 05:00:29,634 ----------------------------------------------------------------------------------------------------\n",
            "2021-02-19 05:00:29,640 Testing using best model ...\n",
            "2021-02-19 05:00:29,647 loading file /content/drive/MyDrive/Colab Notebooks/data/AG_News/models/best-model.pt\n",
            "2021-02-19 05:02:43,099 \t0.8896\n",
            "2021-02-19 05:02:43,103 \n",
            "Results:\n",
            "- F-score (micro) 0.8896\n",
            "- F-score (macro) 0.8895\n",
            "- Accuracy 0.8896\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2     0.9511    0.9721    0.9615      1900\n",
            "           4     0.8554    0.8595    0.8574      1900\n",
            "           3     0.8372    0.8474    0.8423      1900\n",
            "           1     0.9151    0.8795    0.8969      1900\n",
            "\n",
            "   micro avg     0.8896    0.8896    0.8896      7600\n",
            "   macro avg     0.8897    0.8896    0.8895      7600\n",
            "weighted avg     0.8897    0.8896    0.8895      7600\n",
            " samples avg     0.8896    0.8896    0.8896      7600\n",
            "\n",
            "2021-02-19 05:02:43,105 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.4104565382003784,\n",
              "  0.36020976305007935,\n",
              "  0.3414340019226074,\n",
              "  0.330353319644928,\n",
              "  0.32371780276298523,\n",
              "  0.3182004690170288,\n",
              "  0.3148873448371887,\n",
              "  0.312004953622818,\n",
              "  0.30851998925209045,\n",
              "  0.30598127841949463],\n",
              " 'dev_score_history': [0.8677,\n",
              "  0.8813,\n",
              "  0.8828,\n",
              "  0.8857,\n",
              "  0.8873,\n",
              "  0.888,\n",
              "  0.8887,\n",
              "  0.8882,\n",
              "  0.8913,\n",
              "  0.89],\n",
              " 'test_score': 0.8896,\n",
              " 'train_loss_history': [0.6083388389680993,\n",
              "  0.39383019639930705,\n",
              "  0.36673819316515144,\n",
              "  0.35406898864816155,\n",
              "  0.3328147403919056,\n",
              "  0.3353817652792,\n",
              "  0.322695233957842,\n",
              "  0.3257736471523776,\n",
              "  0.32150313759876187,\n",
              "  0.3186222939234096]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHffi15oxENG"
      },
      "source": [
        "!pip install flair\r\n",
        "from flair.models import TextClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrCA_u8ix3Il"
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhrf6QSZyDru"
      },
      "source": [
        "from flair.data import Sentence\r\n",
        "from pathlib import Path\r\n",
        "path = Path('/content/drive/MyDrive/Colab Notebooks/data/AG_News')\r\n",
        "new_clf = TextClassifier.load(path / 'models/best-model.pt')\r\n",
        "classes = {'1' : \"World\", '2' : \"Sports\", '3' : \"Business\", '4' : \"Sci/Tech\"}\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Net5czJB402s"
      },
      "source": [
        "phrase = \"Mohamed Salah and Sadio Mane struck in the space of five minutes near the start of the second half in an away leg played in Budapest's Puskas Arena because of Covid-19 restrictions. It came after the Reds had fallen to three straight defeats in the Premier League - results that have led Klopp to concede defeat in their defence of the English top-flight title. But Tuesday's display was far more like the dominant side of last season, with their greater experience and quality ultimately telling against an error-prone German side.\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXcKyK5D5fi1"
      },
      "source": [
        "sentence = Sentence(phrase)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWGzZfin5irB"
      },
      "source": [
        "new_clf.predict(sentence)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbJ1YUEbyZqL"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX3J7uoh5p2V",
        "outputId": "3e2c5275-d280-4ad1-de4e-b92a022619bc"
      },
      "source": [
        "print(f'This text is belongs to the class {classes[str(sentence.labels[0])[0]]}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This text is belongs to the class Sports\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2gLbDEH5tTI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}